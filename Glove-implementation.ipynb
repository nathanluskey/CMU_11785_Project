{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"clP_uKwfK4VG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648934729222,"user_tz":240,"elapsed":2638,"user":{"displayName":"Bhumika Kapur","userId":"11125944364903117804"}},"outputId":"db5430d3-fe5b-40af-e668-f0d9383de05a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lH9qt9aMLPWr"},"outputs":[],"source":["import sys\n","sys.path.insert(0,'/content/drive/MyDrive/GloveCode')\n","from vectorizer import Vectorizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LvtJ_laoRf1E"},"outputs":[],"source":["import os\n","# corpus=[]\n","# i=0\n","# path = '/content/gdrive/MyDrive/parsed_data'\n","# for file in os.listdir(path):\n","#    with open(path+'/'+file) as f:\n","#     print(file)\n","#     data = f.read()\n","#     data=data.split()\n","#     corpus.extend(data)\n","# print(len(corpus)) \n","# with open('/content/gdrive/MyDrive/corpus', 'w') as writefile:\n","#       for c in corpus:\n","#         writefile.write(\"%s\\n\" % c)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CpYAZoHWaoVq"},"outputs":[],"source":["with open('/content/drive/MyDrive/corpus') as f:\n","  newC=f.read().split(\"\\n\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OagpR9fFOZYn"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","\n","class GloVe(nn.Module):\n","\n","    def __init__(self, vocab_size, embedding_size, x_max, alpha):\n","        super().__init__()\n","        self.weight = nn.Embedding(\n","            num_embeddings=vocab_size,\n","            embedding_dim=embedding_size,\n","            sparse=True\n","        )\n","        self.weight_tilde = nn.Embedding(\n","            num_embeddings=vocab_size,\n","            embedding_dim=embedding_size,\n","            sparse=True\n","        )\n","        self.bias = nn.Parameter(\n","            torch.randn(\n","                vocab_size,\n","                dtype=torch.float,\n","            )\n","        )\n","        self.bias_tilde = nn.Parameter(\n","            torch.randn(\n","                vocab_size,\n","                dtype=torch.float,\n","            )\n","        )\n","        self.weighting_func = lambda x: (x / x_max).float_power(alpha).clamp(0, 1)\n","    \n","    def forward(self, i, j, x):\n","        loss = torch.mul(self.weight(i), self.weight_tilde(j)).sum(dim=1)\n","        loss = (loss + self.bias[i] + self.bias_tilde[j] - x.log()).square()\n","        loss = torch.mul(self.weighting_func(x), loss).mean()\n","        return loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353},"id":"L9Rtu1WBJ15h","executionInfo":{"status":"error","timestamp":1648935922271,"user_tz":240,"elapsed":996,"user":{"displayName":"Bhumika Kapur","userId":"11125944364903117804"}},"outputId":"5c71e6aa-03e0-4453-8b45-d1bcfb93bdca"},"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-1c52cb9be037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m#if not args.first_step_only:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mtrain_glove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-4-1c52cb9be037>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m#args = parse_args()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;31m#if not args.second_step_only:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mcalculate_cooccurrence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-1c52cb9be037>\u001b[0m in \u001b[0;36mload_config\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m#config_filepath = /content/gdrive/MyDrive/gloveCode/config.yaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/gloveCode/config.yaml'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected: '/content/gdrive/MyDrive/gloveCode/config.yaml'"]}],"source":["import argparse\n","import pickle\n","import os\n","from pathlib import Path\n","\n","import yaml\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.optim\n","from tqdm import tqdm\n","\n","from vectorizer import Vectorizer\n","from cooccurrence_entries import CooccurrenceEntries\n","#from glove import GloVe\n","from hdf5_dataloader import HDF5DataLoader\n","\n","\n","def parse_args():\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\n","        \"--first-step-only\",\n","        help=\"only calculate the cooccurrence matrix\",\n","        action=\"store_true\"\n","    )\n","    parser.add_argument(\n","        \"--second-step-only\",\n","        help=\"train the word vectors given the cooccurrence matrix\",\n","        action=\"store_true\"\n","    )\n","    return parser.parse_args()\n","\n","\n","def load_config():\n","    #config_filepath = /content/gdrive/MyDrive/gloveCode/config.yaml\n","    with open('/content/gdrive/MyDrive/gloveCode/config.yaml') as parameters:\n","            config_dict = yaml.safe_load(parameters)\n","    config = argparse.Namespace()\n","    for key, value in config_dict.items():\n","        setattr(config, key, value)\n","    return config\n","\n","\n","def calculate_cooccurrence(config):\n","    with open(config.input_filepath, \"r\") as f:\n","        corpus = f.read().split(\"\\n\")\n","    vectorizer = Vectorizer.from_corpus(\n","        corpus=corpus,\n","        vocab_size=config.vocab_size\n","    )\n","    cooccurrence = CooccurrenceEntries.setup(\n","        corpus=corpus,\n","        vectorizer=vectorizer\n","    )\n","    print(config.cooccurrence_dir)\n","    cooccurrence.build(\n","        window_size=config.window_size,\n","        num_partitions=config.num_partitions,\n","        chunk_size=config.chunk_size,\n","        output_directory=config.cooccurrence_dir\n","    ) \n","\n","\n","def train_glove(config):\n","    dataloader = HDF5DataLoader(\n","        filepath=os.path.join(config.cooccurrence_dir, \"cooccurrence.hdf5\"),\n","        dataset_name=\"cooccurrence\",\n","        batch_size=config.batch_size,\n","        device=config.device\n","    )\n","    model = GloVe(\n","        vocab_size=config.vocab_size,\n","        embedding_size=config.embedding_size,\n","        x_max=config.x_max,\n","        alpha=config.alpha\n","    )\n","    model.to(config.device)\n","    optimizer = torch.optim.Adagrad(\n","        model.parameters(),\n","        lr=config.learning_rate\n","    )\n","    with dataloader.open():\n","        model.train()\n","        losses = []\n","        for epoch in tqdm(range(config.num_epochs)):\n","            epoch_loss = 0\n","            for batch in tqdm(dataloader.iter_batches()):\n","                loss = model(\n","                    batch[0][:, 0],\n","                    batch[0][:, 1],\n","                    batch[1]\n","                )\n","                epoch_loss += loss.detach().item()\n","                loss.backward()\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","            losses.append(epoch_loss)\n","            print(f\"Epoch {epoch}: loss = {epoch_loss}\")\n","            torch.save(model.state_dict(), config.output_filepath)\n","    \n","    plt.plot(losses)\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.show()\n","\n","\n","def main():\n","    #args = parse_args()\n","    config = load_config()\n","    #if not args.second_step_only:\n","    calculate_cooccurrence(config)\n","    #if not args.first_step_only:\n","    train_glove(config)\n","main()"]},{"cell_type":"code","source":["class Network(nn.Module):\n","    def __init__(self): # You can add any extra arguments as you wish\n","        super(Network, self).__init__()\n","        self.embedding = nn.Sequential(\n","            nn.Conv1d(13, 64, 1), \n","            nn.Conv1d(64, 256, 1)\n","        )\n","        \n","        self.lstm = nn.LSTM(256, 256, num_layers=4, bidirectional=True, dropout=0.2) # TODO: # Create a single layer, uni-directional LSTM with hidden_size = 256\n","\n","        self.classification = nn.Sequential(\n","            nn.Linear(512, 2048), \n","            nn.Linear(2048, 41)) \n","\n","    def forward(self, x, lengths_x): # TODO: You need to pass atleast 1 more parameter apart from self and x\n","        x=x.permute(0,2,1)\n","        embedded=self.embedding(x)\n","        embedded=embedded.permute(0,2,1)\n","        packed_input = pack_padded_sequence(embedded, lengths_x, enforce_sorted=False, batch_first=False)# TODO: Pack the input with pack_padded_sequence. Look at the parameters it requires\n","        out1, (out2, out3) = self.lstm(packed_input) \n","        out, lengths  = pad_packed_sequence(out1) \n","\n","        out = self.classification(out)\n","        out = nn.functional.log_softmax(out, dim=2) \n","\n","        \n","        return out, lengths\n","model = Network().to(device)"],"metadata":{"id":"hGhX11lHDiIa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install --upgrade gensim --user"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":266},"id":"jVEGMOsOXs47","executionInfo":{"status":"ok","timestamp":1648935871261,"user_tz":240,"elapsed":7533,"user":{"displayName":"Bhumika Kapur","userId":"11125944364903117804"}},"outputId":"9e08afdf-a58b-42e7-bcdb-433880cb3d13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Collecting gensim\n","  Downloading gensim-4.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n","\u001b[K     |████████████████████████████████| 24.1 MB 44.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.5)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n","Installing collected packages: gensim\n","Successfully installed gensim-4.1.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["gensim"]}}},"metadata":{}}]},{"cell_type":"code","source":["from pathlib import Path\n","import os\n","import argparse\n","import pickle\n","\n","import torch\n","import yaml\n","from gensim.models.keyedvectors import KeyedVectors\n","import gensim.models\n","#from glove import GloVe\n","import h5py\n","\n","\n","def load_config():\n","    with open('/content/drive/MyDrive/GloveCode/config.yaml') as parameters:\n","            config_dict = yaml.safe_load(parameters)\n","    config = argparse.Namespace()\n","    for key, value in config_dict.items():\n","        setattr(config, key, value)\n","    return config\n","\n","\n","def main():\n","    config = load_config()\n","    with open(os.path.join('/content/drive/MyDrive/', \"vocab.pkl\"), \"rb\") as f:\n","        vocab = pickle.load(f)\n","\n","    model = GloVe(\n","        vocab_size=config.vocab_size,\n","        embedding_size=config.embedding_size,\n","        x_max=config.x_max,\n","        alpha=config.alpha\n","    )\n","    model.load_state_dict(torch.load('/content/drive/MyDrive/glove-output'))\n","    \n","    keyed_vectors = gensim.models.keyedvectors.KeyedVectors(vector_size=config.embedding_size)\n","    #print(type(keyed_vectors))\n","    keyed_vectors.add_vectors(\n","        keys=[vocab.get_token(index) for index in range(len(vocab))],\n","        weights=(model.weight.weight.detach()\n","            + model.weight_tilde.weight.detach()).numpy()\n","    )\n","\n","    print(\"get vector\")\n","    print(vocab[\"bhumika\"])\n","    print(len(keyed_vectors.get_vector(\"shall\")))\n","    \n","    # print(\"How similar is company and shall:\")\n","    # print(keyed_vectors.similarity(\"company\", \"shall\"))\n","    # print(\"How similar is million and stock:\")\n","    # print(keyed_vectors.similarity(\"million\", \"stock\"))\n","    # print(\"How similar is financial and date:\")\n","    # print(keyed_vectors.similarity(\"financial\", \"date\"))\n","    # for word in [\"agreement\", \"dollar\", \"stock\"]:\n","    #     print(f\"Most similar words of {word}:\")\n","    #     most_similar_words = [word for word, _ in keyed_vectors.similar_by_word(word)]\n","    #     print(most_similar_words)\n","\n","main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZxvlmYg7QiGf","executionInfo":{"status":"ok","timestamp":1648936595489,"user_tz":240,"elapsed":297,"user":{"displayName":"Bhumika Kapur","userId":"11125944364903117804"}},"outputId":"16ea0504-0ee9-4a27-a872-d3d7f0613f83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["get vector\n","-1\n","100\n"]}]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Glove-implementation.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}