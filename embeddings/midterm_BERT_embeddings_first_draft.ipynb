{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "midterm-BERT-embeddings-first-draft.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WPXx3HH4QF4T"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e1cacc1bb4fb46b4a1c29a92b0b5d32a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_498f49433cd2485d9f5f11c39dfa5bb0",
              "IPY_MODEL_a39714b945a24b76bba16c417d2fae53",
              "IPY_MODEL_e730e16ddf4d4f9b85e60f0eebb753bd"
            ],
            "layout": "IPY_MODEL_d481f9464703443ea32b85fa119f974c"
          }
        },
        "498f49433cd2485d9f5f11c39dfa5bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4a9f9c1b0a448458064a4ea0f8844bc",
            "placeholder": "​",
            "style": "IPY_MODEL_ce1ef93b813546a78d948f22217be46e",
            "value": "Downloading: 100%"
          }
        },
        "a39714b945a24b76bba16c417d2fae53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b83d3c852df24880b50a1d79f33e0f6e",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d0d121509a54ab8bc2c35d7086d5a77",
            "value": 625
          }
        },
        "e730e16ddf4d4f9b85e60f0eebb753bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9994af819c54497482d48f53b312e910",
            "placeholder": "​",
            "style": "IPY_MODEL_de632c66b3ee482c95cb6d7658bec8d3",
            "value": " 625/625 [00:00&lt;00:00, 9.68kB/s]"
          }
        },
        "d481f9464703443ea32b85fa119f974c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4a9f9c1b0a448458064a4ea0f8844bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce1ef93b813546a78d948f22217be46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b83d3c852df24880b50a1d79f33e0f6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d0d121509a54ab8bc2c35d7086d5a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9994af819c54497482d48f53b312e910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de632c66b3ee482c95cb6d7658bec8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d0ca6cdd54347e08788b3522c243b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c1b177733ce41379892111ebc4a8bab",
              "IPY_MODEL_03398400094244c79f449c34881099c8",
              "IPY_MODEL_735c38c1460342dfbc98e58f6d9225a5"
            ],
            "layout": "IPY_MODEL_ec93ae9e7682450bb978bad66126916a"
          }
        },
        "9c1b177733ce41379892111ebc4a8bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c60eb16b362413681184fee3d23c156",
            "placeholder": "​",
            "style": "IPY_MODEL_9ca0d294662948c893e489f8f9b3826a",
            "value": "Downloading: 100%"
          }
        },
        "03398400094244c79f449c34881099c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26b42ae61ae3485c8040fdf188d7bd89",
            "max": 714314041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b9ea4ce985f4eaba2b496fd3952e485",
            "value": 714314041
          }
        },
        "735c38c1460342dfbc98e58f6d9225a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e88e643322d84afb8e865f22d8ba0460",
            "placeholder": "​",
            "style": "IPY_MODEL_d74d4ea385944099b864cae7db5cf45c",
            "value": " 681M/681M [00:17&lt;00:00, 37.9MB/s]"
          }
        },
        "ec93ae9e7682450bb978bad66126916a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c60eb16b362413681184fee3d23c156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ca0d294662948c893e489f8f9b3826a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26b42ae61ae3485c8040fdf188d7bd89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b9ea4ce985f4eaba2b496fd3952e485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e88e643322d84afb8e865f22d8ba0460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d74d4ea385944099b864cae7db5cf45c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d75098c41cab486a8b02985fbb1fc137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca70aac9068946a1970c231bac88c9bb",
              "IPY_MODEL_2cc2ef03d3994fefaf741a864f0af966",
              "IPY_MODEL_e71f617847c8444aa0984174807761ca"
            ],
            "layout": "IPY_MODEL_5e5cb14ed3474431a5ca8ba50d9d41cc"
          }
        },
        "ca70aac9068946a1970c231bac88c9bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb292ea3f82c464f8e1b7649b38a5cfc",
            "placeholder": "​",
            "style": "IPY_MODEL_bf763f9e22f14da0bc408970d7299f92",
            "value": "Downloading: 100%"
          }
        },
        "2cc2ef03d3994fefaf741a864f0af966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29223bcfd8f948f5962b9ab0a160b568",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d006d61a0f4a47cdb96f80272f304379",
            "value": 995526
          }
        },
        "e71f617847c8444aa0984174807761ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d306489b251343168c70c558ceb94e1c",
            "placeholder": "​",
            "style": "IPY_MODEL_89ecb5d77b2743f3a64f4db55285f688",
            "value": " 972k/972k [00:00&lt;00:00, 2.27MB/s]"
          }
        },
        "5e5cb14ed3474431a5ca8ba50d9d41cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb292ea3f82c464f8e1b7649b38a5cfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf763f9e22f14da0bc408970d7299f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29223bcfd8f948f5962b9ab0a160b568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d006d61a0f4a47cdb96f80272f304379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d306489b251343168c70c558ceb94e1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89ecb5d77b2743f3a64f4db55285f688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62a2a026fb4141c6973106bf19b2c9bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73f70fcd76e545d3904d58a01ee15412",
              "IPY_MODEL_14731aca04524a49af614691463d735a",
              "IPY_MODEL_c93344b07e974e849345a25a526ad306"
            ],
            "layout": "IPY_MODEL_3ff420773d3f4a1eb87c95ac06df6901"
          }
        },
        "73f70fcd76e545d3904d58a01ee15412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41781106627c49c08c70759d759f4118",
            "placeholder": "​",
            "style": "IPY_MODEL_dccb6b9be4a94f58a8b195a694e7ba78",
            "value": "Downloading: 100%"
          }
        },
        "14731aca04524a49af614691463d735a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bed7ca77b5e48fb8924ad74187bb53d",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4475df5978ad480aa5abccbd5b656320",
            "value": 29
          }
        },
        "c93344b07e974e849345a25a526ad306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d92968982ac423c868380c6aae798aa",
            "placeholder": "​",
            "style": "IPY_MODEL_c68015b1494b47a294d7064b12df8c33",
            "value": " 29.0/29.0 [00:00&lt;00:00, 527B/s]"
          }
        },
        "3ff420773d3f4a1eb87c95ac06df6901": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41781106627c49c08c70759d759f4118": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dccb6b9be4a94f58a8b195a694e7ba78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bed7ca77b5e48fb8924ad74187bb53d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4475df5978ad480aa5abccbd5b656320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d92968982ac423c868380c6aae798aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c68015b1494b47a294d7064b12df8c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initial setup"
      ],
      "metadata": {
        "id": "3TjHdbR3nbJP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6-SOHWHFGHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f102483d-6f18-4751-8f9a-5a190871e984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 123 kB 9.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 38.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 43.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 46.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 21.2 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 6.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 25.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 40.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 41.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-pretrained-bert --quiet\n",
        "!pip install -qq transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n"
      ],
      "metadata": {
        "id": "ooBn6YeWFMB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to my Drive"
      ],
      "metadata": {
        "id": "-6tqN8P6HtGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOEhkZxUHsTG",
        "outputId": "6927e9ac-c1b7-404e-8635-8fe3e8d4ae8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First attempt - Useless"
      ],
      "metadata": {
        "id": "WPXx3HH4QF4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(marked_text, tokenizer):\n",
        "    tokenized_text = tokenizer.tokenize(marked_text)\n",
        "    segments_ids = [1] * len(tokenized_text)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    return tokenized_text, segments_ids, indexed_tokens\n",
        " "
      ],
      "metadata": {
        "id": "GzSSDmcI4vmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_token_embeddings(model, indexed_tokens, segments_ids):\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "    model.eval()\n",
        "    # Predict hidden states features for each layer\n",
        "    with torch.no_grad():\n",
        "        encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
        "\n",
        "    # Concatenate the tensors for all layers. We use `stack` here to\n",
        "    # create a new dimension in the tensor.\n",
        "    token_embeddings = torch.stack(encoded_layers, dim=0)\n",
        "\n",
        "    # Remove dimension 1, the \"batches\".\n",
        "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "    # Swap dimensions 0 and 1.\n",
        "    token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "    token_embeddings.size()\n",
        "\n",
        "    # Stores the token vectors, with shape [23 x 768]\n",
        "    token_vecs_sum = []\n",
        "\n",
        "    # `token_embeddings` is a [23 x 12 x 768] tensor.\n",
        "\n",
        "    # For each token in the sentence...\n",
        "    for token in token_embeddings:\n",
        "\n",
        "        # `token` is a [12 x 768] tensor\n",
        "        # Sum the vectors from the last four layers.\n",
        "        sum_vec = torch.sum(token[-4:], dim=0)\n",
        "        \n",
        "        # Use `sum_vec` to represent `token`.\n",
        "        token_vecs_sum.append(sum_vec)\n",
        "    return token_vecs_sum\n",
        "\n"
      ],
      "metadata": {
        "id": "xFEyyIas5Bgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sentence_embeddings(model, indexed_tokens, segments_ids):\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "    model.eval()\n",
        "    # Predict hidden states features for each layer\n",
        "    with torch.no_grad():\n",
        "        encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
        "\n",
        "    # `token_vecs` is a tensor with shape [23 x 768]\n",
        "    token_vecs = encoded_layers[11][0]\n",
        "\n",
        "    # Calculate the average of all 23 token vectors.\n",
        "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "    \n",
        "    return sentence_embedding\n",
        "\n"
      ],
      "metadata": {
        "id": "iCkCAtUl5JOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_corpus(corpus):\n",
        "    \"\"\" Split the corpus into multiple sentences and mark them with [CLS] and [SEP] tags.\n",
        "    Returns:\n",
        "    marked_sentences: \n",
        "    lengths: \n",
        "    \"\"\"\n",
        "\n",
        "    corpus = \" \" + corpus\n",
        "    sentences = corpus.split('<eos>')[:-1]\n",
        "    marked_sentences = [\"[CLS]\" + s + \"[SEP]\" for s in sentences]\n",
        "    lengths = [len(s) for s in marked_sentences]\n",
        "    return marked_sentences, lengths\n",
        "\n",
        "def tokenize_corpus(bert_model, bert_tokenizer, marked_sentences):\n",
        "    word_embeddings = []\n",
        "    sentence_embeddings = []\n",
        "    for sentence in marked_sentences:\n",
        "\n",
        "        tokenized_text, segments_ids, indexed_tokens = tokenize(sentence, bert_tokenizer)\n",
        "        token_vecs_sum = generate_token_embeddings(bert_model, indexed_tokens, segments_ids)\n",
        "        sentence_embedding = generate_sentence_embeddings(bert_model, indexed_tokens, segments_ids)\n",
        "\n",
        "        # print('Sentence: {}', sentence)\n",
        "        # print('Number of tokens: {} Shape of each token embedding: {}'.format(len(token_vecs_sum), token_vecs_sum[0].shape))\n",
        "        # print('Shape of each sentence embedding: {}\\n'.format(sentence_embedding.shape))\n",
        "\n",
        "        word_embeddings.append(token_vecs_sum)\n",
        "        sentence_embeddings.append(sentence_embedding)\n",
        "\n",
        "    return word_embeddings, sentence_embeddings\n"
      ],
      "metadata": {
        "id": "VGOjiuoFQ2Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218,
          "referenced_widgets": [
            "e1cacc1bb4fb46b4a1c29a92b0b5d32a",
            "498f49433cd2485d9f5f11c39dfa5bb0",
            "a39714b945a24b76bba16c417d2fae53",
            "e730e16ddf4d4f9b85e60f0eebb753bd",
            "d481f9464703443ea32b85fa119f974c",
            "b4a9f9c1b0a448458064a4ea0f8844bc",
            "ce1ef93b813546a78d948f22217be46e",
            "b83d3c852df24880b50a1d79f33e0f6e",
            "0d0d121509a54ab8bc2c35d7086d5a77",
            "9994af819c54497482d48f53b312e910",
            "de632c66b3ee482c95cb6d7658bec8d3",
            "8d0ca6cdd54347e08788b3522c243b96",
            "9c1b177733ce41379892111ebc4a8bab",
            "03398400094244c79f449c34881099c8",
            "735c38c1460342dfbc98e58f6d9225a5",
            "ec93ae9e7682450bb978bad66126916a",
            "9c60eb16b362413681184fee3d23c156",
            "9ca0d294662948c893e489f8f9b3826a",
            "26b42ae61ae3485c8040fdf188d7bd89",
            "0b9ea4ce985f4eaba2b496fd3952e485",
            "e88e643322d84afb8e865f22d8ba0460",
            "d74d4ea385944099b864cae7db5cf45c",
            "d75098c41cab486a8b02985fbb1fc137",
            "ca70aac9068946a1970c231bac88c9bb",
            "2cc2ef03d3994fefaf741a864f0af966",
            "e71f617847c8444aa0984174807761ca",
            "5e5cb14ed3474431a5ca8ba50d9d41cc",
            "fb292ea3f82c464f8e1b7649b38a5cfc",
            "bf763f9e22f14da0bc408970d7299f92",
            "29223bcfd8f948f5962b9ab0a160b568",
            "d006d61a0f4a47cdb96f80272f304379",
            "d306489b251343168c70c558ceb94e1c",
            "89ecb5d77b2743f3a64f4db55285f688",
            "62a2a026fb4141c6973106bf19b2c9bf",
            "73f70fcd76e545d3904d58a01ee15412",
            "14731aca04524a49af614691463d735a",
            "c93344b07e974e849345a25a526ad306",
            "3ff420773d3f4a1eb87c95ac06df6901",
            "41781106627c49c08c70759d759f4118",
            "dccb6b9be4a94f58a8b195a694e7ba78",
            "1bed7ca77b5e48fb8924ad74187bb53d",
            "4475df5978ad480aa5abccbd5b656320",
            "5d92968982ac423c868380c6aae798aa",
            "c68015b1494b47a294d7064b12df8c33"
          ]
        },
        "id": "K0dYihkv9tA2",
        "outputId": "f553d4de-7573-4a4a-b27e-f0bcf098cad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1cacc1bb4fb46b4a1c29a92b0b5d32a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d0ca6cdd54347e08788b3522c243b96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/972k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d75098c41cab486a8b02985fbb1fc137"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62a2a026fb4141c6973106bf19b2c9bf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus =  \"Disposing of certain hazardous wastes without necessary authorization and without compliance with regulatory requirements <eos> the complaint seeks a court order directing navajo to comply with these regulatory standards and civil penalties for the alleged non-compliance navajo has answered the complaint <eos>\"\n",
        "marked_sentences, lengths = split_corpus(corpus)\n",
        "word_embeddings, sentence_embeddings = tokenize_corpus(bert_model, bert_tokenizer, marked_sentences)"
      ],
      "metadata": {
        "id": "JEjyXRqXCC3g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "4b4e41e0-2f55-4369-b755-6eb16928ddc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-fd92310030d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m\"Disposing of certain hazardous wastes without necessary authorization and without compliance with regulatory requirements <eos> the complaint seeks a court order directing navajo to comply with these regulatory standards and civil penalties for the alleged non-compliance navajo has answered the complaint <eos>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmarked_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mword_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarked_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-0a7819d564ba>\u001b[0m in \u001b[0;36mtokenize_corpus\u001b[0;34m(bert_model, bert_tokenizer, marked_sentences)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtokenized_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegments_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexed_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtoken_vecs_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_token_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexed_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegments_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0msentence_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_sentence_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexed_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegments_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-bb3311027461>\u001b[0m in \u001b[0;36mgenerate_token_embeddings\u001b[0;34m(model, indexed_tokens, segments_ids)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Concatenate the tensors for all layers. We use `stack` here to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# create a new dimension in the tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtoken_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Remove dimension 1, the \"batches\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: stack(): argument 'tensors' (position 1) must be tuple of Tensors, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sentence_embeddings), len(sentence_embeddings[0]), len(sentence_embeddings[1]))"
      ],
      "metadata": {
        "id": "v6AJfd5ZCC61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "41bc11e3-c88b-49db-f458-b14c990b3b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d3adbfc9422d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sentence_embeddings' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eJbVxSLuwy48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split dataset"
      ],
      "metadata": {
        "id": "WTwjmTh4j5WZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "root = '/content/drive/MyDrive/11785_Project/Programming/Data/fiqa2018/'\n",
        "df1 = pd.read_csv(f\"{root}FiQA_ABSA_task1/task1_headline_ABSA_train.csv\")\n",
        "df2 = pd.read_csv(f\"{root}FiQA_ABSA_task1/task1_post_ABSA_train.csv\")\n",
        "df = pd.concat([df1, df2])\n",
        "\n",
        "df_test1 = pd.read_csv(f\"{root}FIQA_ABSA_task1_test/task1_post_ABSA_test.csv\")\n",
        "df_test2 = pd.read_csv(f\"{root}FIQA_ABSA_task1_test/task1_headline_ABSA_test.csv\")\n",
        "df_test = pd.concat([df_test1, df_test2])\n",
        "\n"
      ],
      "metadata": {
        "id": "m-xdJTh4j3mT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "b93883ef-c443-4412-f886-ade3b42ea9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4df5920fb21a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/11785_Project/Programming/Data/fiqa2018/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{root}FiQA_ABSA_task1/task1_headline_ABSA_train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{root}FiQA_ABSA_task1/task1_post_ABSA_train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/11785_Project/Programming/Data/fiqa2018/FiQA_ABSA_task1/task1_headline_ABSA_train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment for classification task\n",
        "# df[\"sentiment_score\"] = df[\"sentiment_score\"].apply(lambda x: 1 if x>0 else 0)\n"
      ],
      "metadata": {
        "id": "_Gs-ue0Lj38x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val = train_test_split(df, test_size = 0.18, random_state = 10)\n",
        "len(df_train), len(df_val), len(df_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsvblCXcUvfu",
        "outputId": "cd56ccd8-3986-4a4c-d609-01ef4c6ae544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(911, 200, 192)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "zBqxJ1TM5Z4I",
        "outputId": "40cbb45a-ad85-4c6b-9c6f-b2963fff921a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0     id                                           sentence  \\\n",
              "363         363  16692       NaturalGas Settles At 3-year Low $DBO $BNO     \n",
              "491         491  17562  $FB & $TSLA cracking lower early. $short #corr...   \n",
              "151         151    539  Sainsbury sales slip again as price pressures ...   \n",
              "656         656  19015  $JD down 20% in after-hour market. anyone care...   \n",
              "520         520  17831                $FB trend, hits mid 110's and drops   \n",
              "\n",
              "                          snippets     target  sentiment_score  \\\n",
              "363          Settles At 3-year Low        DBO           -0.563   \n",
              "491            cracking lower earl       TSLA           -0.511   \n",
              "151          pressures take a toll  Sainsbury           -0.303   \n",
              "656  down 20% in after-hour market         JD           -0.551   \n",
              "520       hits mid 110's and drops         FB           -0.343   \n",
              "\n",
              "                                         aspects  \n",
              "363                   Stock/Price Action/Bearish  \n",
              "491  Stock/Price Action/Bearish/Bearish Behavior  \n",
              "151                           Stock/Price Action  \n",
              "656  Stock/Price Action/Bearish/Bearish Behavior  \n",
              "520  Stock/Price Action/Bearish/Bearish Behavior  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-746c2f05-0848-40d5-b3dc-24ea1e75a383\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>snippets</th>\n",
              "      <th>target</th>\n",
              "      <th>sentiment_score</th>\n",
              "      <th>aspects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>363</td>\n",
              "      <td>16692</td>\n",
              "      <td>NaturalGas Settles At 3-year Low $DBO $BNO</td>\n",
              "      <td>Settles At 3-year Low</td>\n",
              "      <td>DBO</td>\n",
              "      <td>-0.563</td>\n",
              "      <td>Stock/Price Action/Bearish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>491</td>\n",
              "      <td>17562</td>\n",
              "      <td>$FB &amp; $TSLA cracking lower early. $short #corr...</td>\n",
              "      <td>cracking lower earl</td>\n",
              "      <td>TSLA</td>\n",
              "      <td>-0.511</td>\n",
              "      <td>Stock/Price Action/Bearish/Bearish Behavior</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>151</td>\n",
              "      <td>539</td>\n",
              "      <td>Sainsbury sales slip again as price pressures ...</td>\n",
              "      <td>pressures take a toll</td>\n",
              "      <td>Sainsbury</td>\n",
              "      <td>-0.303</td>\n",
              "      <td>Stock/Price Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>656</th>\n",
              "      <td>656</td>\n",
              "      <td>19015</td>\n",
              "      <td>$JD down 20% in after-hour market. anyone care...</td>\n",
              "      <td>down 20% in after-hour market</td>\n",
              "      <td>JD</td>\n",
              "      <td>-0.551</td>\n",
              "      <td>Stock/Price Action/Bearish/Bearish Behavior</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>520</td>\n",
              "      <td>17831</td>\n",
              "      <td>$FB trend, hits mid 110's and drops</td>\n",
              "      <td>hits mid 110's and drops</td>\n",
              "      <td>FB</td>\n",
              "      <td>-0.343</td>\n",
              "      <td>Stock/Price Action/Bearish/Bearish Behavior</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-746c2f05-0848-40d5-b3dc-24ea1e75a383')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-746c2f05-0848-40d5-b3dc-24ea1e75a383 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-746c2f05-0848-40d5-b3dc-24ea1e75a383');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysing data (to get max length for padding)"
      ],
      "metadata": {
        "id": "rCtuttTWrOAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = df.sentence.to_list()\n",
        "sentiment_scores = torch.tensor(df.sentiment_score.to_list())\n",
        "print(sentences[:2], sentiment_scores[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjQC4tqFrMrn",
        "outputId": "ca44da08-2d55-4997-921a-127dbd9f16f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Royal Mail chairman Donald Brydon set to step down', 'Stakes High for AstraZeneca Heart Drug Facing Tough Competition'] tensor([-0.3740, -0.2400])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_lens = [len(bert_tokenizer.encode(sentence)) for sentence in sentences]\n",
        "max_length = max(token_lens)\n",
        "max_length = int(np.power(2, np.ceil(np.log2(max_length)))) #  Raise maxlength to the next power of 2\n",
        "max_length"
      ],
      "metadata": {
        "id": "ov9XuE1oRyut",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "2a935e66-6fce-4a9c-d40c-d80a15b9e2ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-be9b1726f180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoken_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#  Raise maxlength to the next power of 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-be9b1726f180>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoken_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#  Raise maxlength to the next power of 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bert_tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence = sentences[0]\n",
        "sample_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rADd6PxarMu9",
        "outputId": "74beb096-47a5-485c-e649-5dc54326dbf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Royal Mail chairman Donald Brydon set to step down'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "sentence_encoding = bert_tokenizer.encode_plus(sample_sentence, return_tensors = 'pt', max_length = 1024) # Return encoding as pytorch tensor\n",
        "input_ids, attention_mask = sentence_encoding['input_ids'], sentence_encoding['attention_mask']\n",
        "(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWr-8NMMxRTU",
        "outputId": "1c3f3327-1a98-4f62-fda9-d13ba49a801b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  1787, 11508,  3931,  5554,   139,  1616,  3842,  1383,  1106,\n",
              "          2585,  1205,   102]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SentimentLinear - BERT"
      ],
      "metadata": {
        "id": "LlPxFM3jR3Rf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "fYSo2C9u93D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FiQaSamples(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, partition, sentences, sentiment_scores, tokenizer, max_len):\n",
        "    self.sentences = sentences\n",
        "    self.sentiment_scores = sentiment_scores\n",
        "    assert len(sentences) == len(sentiment_scores)\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.length = len(self.sentences)\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    sentence = self.sentences[index]\n",
        "    score = self.sentiment_scores[index]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      sentence,\n",
        "      max_length=self.max_len,\n",
        "      padding='max_length',\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return encoding['input_ids'].flatten(), encoding['attention_mask'].flatten(), torch.tensor(score, dtype = torch.float)"
      ],
      "metadata": {
        "id": "X0d65jvD95bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_sentences, train_scores = df_train.sentence.to_list(), df_train.sentiment_score.to_list()\n",
        "val_sentences, val_scores = df_val.sentence.to_list(), df_val.sentiment_score.to_list()\n",
        "\n",
        "train_data = FiQaSamples('train', train_sentences, train_scores, bert_tokenizer, 128)\n",
        "val_data = FiQaSamples('dev', val_sentences, val_scores, bert_tokenizer, 128)\n",
        "# test_data = FiQaSamples('test_order.csv')\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=1) # TODO: Define the train loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=1,) # TODO: Define the val loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "# test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=1, collate_fn=LibriSamplesTest.collate_fn ) # TODO: Define the test loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Batch size: \", batch_size)\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "# print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))\n",
        "print(\"Device: \", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvAaVdxi95mM",
        "outputId": "9d2c2a62-46d2-40f7-df04-6a399eaa4ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  32\n",
            "Train dataset samples = 911, batches = 29\n",
            "Val dataset samples = 200, batches = 7\n",
            "Device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ],
      "metadata": {
        "id": "s3uVrLI9Q38j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://srinivas-yeeda.medium.com/sentiment-analysis-using-word2vec-and-glove-embeddings-5ad7d50ddb0d\n",
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out1 = nn.Linear(self.bert.config.hidden_size, 2048)\n",
        "    self.out2 = nn.Linear(2048, 1024)\n",
        "    self.out3 = nn.Linear(1024, 1)\n",
        "    self.gelu = nn.GELU()\n",
        "    self.sigmoid = nn.Sigmoid() # TODO: Remove\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )[1]\n",
        "    output = self.out1(output)\n",
        "    output = self.gelu(output)\n",
        "    output = self.out2(output)\n",
        "    output = self.gelu(output)\n",
        "    output = self.out3(output)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "q5UEaGka5WYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Validation functions"
      ],
      "metadata": {
        "id": "eR7OWA96Qp4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_train(model, optimizer, criterion, scheduler, train_loader):\n",
        "    torch.cuda.empty_cache()\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "    model.train()    \n",
        "    total_loss = 0\n",
        "\n",
        "    total_ele = 0\n",
        "    for i, (input_ids, attention_mask, y) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "          )\n",
        "        \n",
        "        outputs = outputs.squeeze() # TODO: May have to remove this\n",
        "        loss = criterion(outputs, y)\n",
        "\n",
        "        total_loss += float(loss.item()) \n",
        "        total_ele += int(len(y))\n",
        "        batch_bar.set_postfix(\n",
        "          loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "          lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])),\n",
        "          total_ele=\"{}\".format(int(total_ele))\n",
        "          )\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        batch_bar.update() # Update tqdm bar\n",
        "        \n",
        "    scheduler.step()\n",
        "    batch_bar.close() # You need this to close the tqdm bar\n",
        "    \n",
        "    print(\"Train Loss: {}\".format(total_loss / len(train_loader)))\n",
        "\n",
        "def run_validation(model, val_loader):\n",
        "    torch.cuda.empty_cache()\n",
        "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "    model.eval()    \n",
        "    correct_pred = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    total_ele = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (input_ids, attention_mask, y) in enumerate(val_loader):\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "              )\n",
        "            \n",
        "            outputs = outputs.squeeze() # TODO: May have to remove this\n",
        "            loss = criterion(outputs, y)\n",
        "            total_loss += float(loss.item()) \n",
        "\n",
        "            batch_bar.set_postfix(\n",
        "              lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])),\n",
        "              )\n",
        "            \n",
        "            batch_bar.update() # Update tqdm bar\n",
        "            \n",
        "        batch_bar.close() # You need this to close the tqdm bar\n",
        "        \n",
        "        print(\"Val Loss: {}\".format(total_loss / len(val_loader)))"
      ],
      "metadata": {
        "id": "l5cFhuu27KWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "epochs = 10\n",
        "\n",
        "model = SentimentClassifier()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8sEgDd75Wem",
        "outputId": "60b6514a-b7f8-4c4b-e1f6-91bc4487d031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    run_train(model, optimizer, criterion, scheduler, train_loader)\n",
        "    run_validation(model, val_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7GRSjEQ7sQW",
        "outputId": "3bab015d-c1be-4588-adf8-80640ffd35fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.18358829191752843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.4068537359607631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.17013397174222128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.16777667865670962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.16994145938328334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.16144687297015353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.1700380550963538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1632635005075356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.17042745649814606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.16149365054122333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.17002015667302267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.16048174043153896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.17037384637764522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1608468366080317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.17000441678932735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.160950122722264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.16999431167330062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1605138049043458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.16998342956815446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.16087729766451078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nXInDmvUjowJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SentimentRNN - BERT"
      ],
      "metadata": {
        "id": "2tRtv8LqOrE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BERT_EMBEDDING_SIZE = 768\n",
        "bert_model = BertModel.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n74OC-pwO1nP",
        "outputId": "9fa3a937-bb36-4c92-ae4c-aacd4c567ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "ohBxpfSYPzCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FiQaSamplesBertWord(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, partition, sentences, sentiment_scores, tokenizer, max_len):\n",
        "    self.sentences = sentences\n",
        "    self.sentiment_scores = sentiment_scores\n",
        "    assert len(sentences) == len(sentiment_scores)\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.length = len(self.sentences)\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    sentence = self.sentences[index]\n",
        "    score = self.sentiment_scores[index]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      sentence,\n",
        "      max_length=self.max_len,\n",
        "      padding='max_length',\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return encoding['input_ids'].flatten(), encoding['attention_mask'].flatten(), torch.tensor(score, dtype = torch.float)"
      ],
      "metadata": {
        "id": "TIDcvbNEO1rR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_sentences, train_scores = df_train.sentence.to_list(), df_train.sentiment_score.to_list()\n",
        "val_sentences, val_scores = df_val.sentence.to_list(), df_val.sentiment_score.to_list()\n",
        "\n",
        "train_data = FiQaSamplesBertWord('train', train_sentences, train_scores, bert_tokenizer, 128)\n",
        "val_data = FiQaSamplesBertWord('dev', val_sentences, val_scores, bert_tokenizer, 128)\n",
        "# test_data = FiQaSamplesBertWord('test_order.csv')\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=1) # TODO: Define the train loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=1,) # TODO: Define the val loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "# test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=1, collate_fn=LibriSamplesTest.collate_fn ) # TODO: Define the test loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Batch size: \", batch_size)\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "# print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))\n",
        "print(\"Device: \", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdX-c02IO13q",
        "outputId": "1129e9a9-fa0a-43d5-b15c-2f866358218d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  32\n",
            "Train dataset samples = 911, batches = 29\n",
            "Val dataset samples = 200, batches = 7\n",
            "Device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ],
      "metadata": {
        "id": "fZsaBQnYP2SS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/code/arunmohan003/sentiment-analysis-using-lstm-pytorch/notebook\n",
        "class SentimentBertRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SentimentBertRNN, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.hidden_size = 128\n",
        "        self.lstm = nn.LSTM(input_size=BERT_EMBEDDING_SIZE, hidden_size=self.hidden_size, num_layers=2, batch_first=True)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc = nn.Linear(self.hidden_size, 1)\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # x is a list of vector (num of tokens, emb_dim - hyperparam)\n",
        "        batch_size = input_ids.shape[0]\n",
        "        out = self.bert(input_ids = input_ids, attention_mask = attention_mask)[0]\n",
        "        out = out.contiguous().view(-1, self.hidden_size)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        out = out.view(batch_size, -1)\n",
        "        out = out[:, -1] # get last batch of labels\n",
        "        return out"
      ],
      "metadata": {
        "id": "9_8iZe8xO17I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and validation functions"
      ],
      "metadata": {
        "id": "8FR7JdnoP6ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_train(model, optimizer, criterion, scheduler, train_loader):\n",
        "    torch.cuda.empty_cache()\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "    model.train()    \n",
        "    total_loss = 0\n",
        "\n",
        "    total_ele = 0\n",
        "    for i, (input_ids, attention_mask, y) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "          )\n",
        "        \n",
        "        outputs = outputs.squeeze() # TODO: May have to remove this\n",
        "        loss = criterion(outputs, y)\n",
        "\n",
        "        total_loss += float(loss.item()) \n",
        "        total_ele += int(len(y))\n",
        "        batch_bar.set_postfix(\n",
        "          loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "          lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])),\n",
        "          total_ele=\"{}\".format(int(total_ele))\n",
        "          )\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        batch_bar.update() # Update tqdm bar\n",
        "        \n",
        "    scheduler.step()\n",
        "    batch_bar.close() # You need this to close the tqdm bar\n",
        "    \n",
        "    print(\"Train Loss: {}\".format(total_loss / len(train_loader)))\n",
        "\n",
        "def run_validation(model, val_loader):\n",
        "    torch.cuda.empty_cache()\n",
        "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "    model.eval()    \n",
        "    correct_pred = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    total_ele = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (input_ids, attention_mask, y) in enumerate(val_loader):\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "              )\n",
        "            \n",
        "            outputs = outputs.squeeze() # TODO: May have to remove this\n",
        "            loss = criterion(outputs, y)\n",
        "            total_loss += float(loss.item()) \n",
        "\n",
        "            batch_bar.set_postfix(\n",
        "              lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])),\n",
        "              )\n",
        "            \n",
        "            batch_bar.update() # Update tqdm bar\n",
        "            \n",
        "        batch_bar.close() # You need this to close the tqdm bar\n",
        "        \n",
        "        print(\"Val Loss: {}\".format(total_loss / len(val_loader)))"
      ],
      "metadata": {
        "id": "GsZBzU-iOvaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "epochs = 10\n",
        "\n",
        "model = SentimentBertRNN()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdrIvyTdOvk3",
        "outputId": "10605de8-e821-4c7d-9c96-2a7d74594be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets train!"
      ],
      "metadata": {
        "id": "XyxONyeOP-JF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    run_train(model, optimizer, criterion, scheduler, train_loader)\n",
        "    run_validation(model, val_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r4QE6b8PBDa",
        "outputId": "448c8ccc-8c5b-4906-c825-03d516b63a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.8752116763900066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.17607808538845607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.18389656677328306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.17218721125807082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.18046144164841751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.16996091178485326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.17665653187653113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.17563885237489427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1673661090176681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.17287699239594595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1738741408134329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.17703682609966823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.16847693868752184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.17194960585662297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.16885116619282756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.16994784346648625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.16396602397334986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.17066440199102675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.16824036682474203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.1702498346567154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SentimentRNN - Word2Vec"
      ],
      "metadata": {
        "id": "4gNdoPVKGy90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "EMBED_DIMENSION = 300\n",
        "EMBED_MAX_NORM = 1"
      ],
      "metadata": {
        "id": "j-IeCrRkE89_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some necessary functions"
      ],
      "metadata": {
        "id": "yF5rUmeFQPSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Models\n",
        "\n",
        "class CBOW_Model(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementation of CBOW model described in paper:\n",
        "    https://arxiv.org/abs/1301.3781\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size: int):\n",
        "        super(CBOW_Model, self).__init__()\n",
        "        self.embeddings = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=EMBED_DIMENSION,\n",
        "            max_norm=EMBED_MAX_NORM,\n",
        "        )\n",
        "        self.linear = nn.Linear(\n",
        "            in_features=EMBED_DIMENSION,\n",
        "            out_features=vocab_size,\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs_):\n",
        "        x = self.embeddings(inputs_)\n",
        "        x = x.mean(axis=1)\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SkipGram_Model(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementation of Skip-Gram model described in paper:\n",
        "    https://arxiv.org/abs/1301.3781\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size: int):\n",
        "        super(SkipGram_Model, self).__init__()\n",
        "        self.embeddings = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=EMBED_DIMENSION,\n",
        "            max_norm=EMBED_MAX_NORM,\n",
        "        )\n",
        "        self.linear = nn.Linear(\n",
        "            in_features=EMBED_DIMENSION,\n",
        "            out_features=vocab_size,\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs_):\n",
        "        # print(f'input shape: {inputs_.shape}')\n",
        "        # print(f'input: {inputs_}')\n",
        "        x = self.embeddings(inputs_)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "FQeGBzIDG2ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec Utility Function"
      ],
      "metadata": {
        "id": "eIdlLEGyQVQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_dir = '/content/drive/MyDrive/11785_Project/Programming/Data/Project/word2vec/'\n",
        "# vocab = torch.load(f'{word2vec_dir}vocab.pt')\n",
        "# model = torch.load(f'{word2vec_dir}model.pt')\n",
        "\n",
        "# # embedding from first model layer\n",
        "# embeddings = list(model.parameters())[0]\n",
        "# embeddings = embeddings.cpu().detach().numpy()\n",
        "\n",
        "# # normalization\n",
        "# norms = (embeddings * 2).sum(axis=1) * (1 / 2)\n",
        "# norms = np.reshape(norms, (len(norms), 1))\n",
        "# embeddings_norm = embeddings / norms\n",
        "# embeddings_norm.shape\n",
        "\n",
        "# def get_word_embedding(word: str):\n",
        "#     word_id = vocab[word]\n",
        "#     if word_id == 0:\n",
        "#         # print(\"Out of vocabulary word\")\n",
        "#         return torch.zeros(embeddings_norm.shape[1], 1)\n",
        "\n",
        "#     word_vec = embeddings_norm[word_id]\n",
        "#     word_vec = np.reshape(word_vec, (len(word_vec), 1))\n",
        "#     return word_vec\n",
        "\n",
        "# for w in ['burden', 'deliverable', 'domain']:\n",
        "#     embedding = get_word_embedding(w)\n",
        "\n",
        "#     print(f'{w} has embedding {embedding.shape}')"
      ],
      "metadata": {
        "id": "zV8ioKWV49xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "JKISCkcTQZ8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FiQaSamplesWord2Vec(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, partition, sentences, sentiment_scores, get_word_embedding, max_len):\n",
        "    self.sentences = sentences\n",
        "    self.sentiment_scores = sentiment_scores\n",
        "    self.model = get_word_embedding\n",
        "    assert len(sentences) == len(sentiment_scores)\n",
        "    self.length = len(self.sentences)\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    sentence = self.sentences[index]\n",
        "    score = self.sentiment_scores[index]\n",
        "    tokens = sentence\n",
        "    # Tokens is a list of strings\n",
        "    embedding = np.array([np.array(self.model(token)) for token in sentence.split()])\n",
        "    return torch.tensor(embedding).squeeze(), torch.tensor(score, dtype = torch.float)\n",
        "\n",
        "  def collate_fn(batch):\n",
        "    batch_x = [emb for emb, y in batch]\n",
        "    batch_y = [y for emb, y in batch]\n",
        "\n",
        "    batch_x_pad = pad_sequence(batch_x, batch_first = True) \n",
        "    lengths_x = [x.shape[0] for x in batch_x]\n",
        "\n",
        "    return batch_x_pad, lengths_x, torch.tensor(batch_y)"
      ],
      "metadata": {
        "id": "qQ61B9H-5M8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 32\n",
        "# train_sentences, train_scores = df_train.sentence.to_list(), df_train.sentiment_score.to_list()\n",
        "# val_sentences, val_scores = df_val.sentence.to_list(), df_val.sentiment_score.to_list()\n",
        "\n",
        "# train_data = FiQaSamplesWord2Vec('train', train_sentences, train_scores, get_word_embedding, 128)\n",
        "# val_data = FiQaSamplesWord2Vec('dev', val_sentences, val_scores, get_word_embedding, 128)\n",
        "# # test_data = FiQaSamples('test_order.csv')\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=1, collate_fn=FiQaSamplesWord2Vec.collate_fn) # TODO: Define the train loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "# val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=1, collate_fn=FiQaSamplesWord2Vec.collate_fn) # TODO: Define the val loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "# # test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=1, collate_fn=LibriSamplesTest.collate_fn ) # TODO: Define the test loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# print(\"Batch size: \", batch_size)\n",
        "# print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "# print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "# # print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))\n",
        "# print(\"Device: \", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "L31U-aVwKXgL",
        "outputId": "8bbfbd99-b51a-4114-b5f4-185e7d051ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5f9be19f8df2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFiQaSamplesWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_word_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFiQaSamplesWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dev'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_word_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# test_data = FiQaSamples('test_order.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_word_embedding' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ],
      "metadata": {
        "id": "Qji2hUfDQdQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/code/arunmohan003/sentiment-analysis-using-lstm-pytorch/notebook\n",
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SentimentRNN,self).__init__()\n",
        "        self.hidden_size = 128\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=self.hidden_size, num_layers=2, bidirectional = True, batch_first=True)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc = nn.Linear(self.hidden_size*2, 1)\n",
        "        \n",
        "    def forward(self, x, lx):\n",
        "        # x is a list of vector (num of tokens, emb_dim - hyperparam)\n",
        "        batch_size = x.shape[0]\n",
        "        packed_input = pack_padded_sequence(x, lx, batch_first = True, enforce_sorted=False) \n",
        "        output, (hidden_state, cell_state) = self.lstm(packed_input) \n",
        "        out, lengths  = pad_packed_sequence(output, batch_first = True)\n",
        "        out = out.contiguous().view(-1, self.hidden_size*2)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        out = out.view(batch_size, -1)\n",
        "        out = out[:, -1] # get last batch of labels\n",
        "        return out, lengths\n"
      ],
      "metadata": {
        "id": "FuXbfYbZHSUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and validation functions"
      ],
      "metadata": {
        "id": "8dBjM9TvQfz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_train(model, train_loader, batch_size, optimizer, criterion, scheduler, epoch, epochs):\n",
        "  torch.cuda.empty_cache()\n",
        "  model.train()\n",
        "  batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "\n",
        "  num_correct = 0\n",
        "  total_loss = 0\n",
        "\n",
        "  for i, (x, lx, y) in enumerate(train_loader):\n",
        "      torch.cuda.empty_cache() # Use this often\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      outputs, lengths = model(x, lx)\n",
        "      loss = criterion(outputs, y)\n",
        "      total_loss += float(loss)\n",
        "      batch_bar.set_postfix(\n",
        "          loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "          lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "      \n",
        "      # Another couple things you need for FP16. \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "      batch_bar.update() # Update tqdm bar\n",
        "  scheduler.step() # We told scheduler T_max that we'd call step() (len(train_loader) * epochs) many times.\n",
        "  batch_bar.close() # You need this to close the tqdm bar\n",
        "\n",
        "  print(\"Epoch {}/{}: Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n",
        "      epoch + 1,\n",
        "      epochs,\n",
        "      float(total_loss / len(train_loader)),\n",
        "      float(optimizer.param_groups[0]['lr'])))\n",
        "  \n",
        "\n",
        "\n",
        "def run_validation(model, val_loader):\n",
        "  torch.cuda.empty_cache() # Use this often\n",
        "  model.eval()\n",
        "  batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "  total_loss = 0\n",
        "  with torch.no_grad():\n",
        "      for i, (x, lx, y) in enumerate(val_loader):\n",
        "          torch.cuda.empty_cache() # Use this often\n",
        "          x = x.to(device)\n",
        "          y = y.to(device)\n",
        "\n",
        "          outputs, lengths = model(x, lx)\n",
        "          loss = criterion(outputs, y)\n",
        "          total_loss += loss\n",
        "          batch_bar.set_postfix(dist=\"{:.04f}\".format(total_loss / (i + 1)))\n",
        "\n",
        "          batch_bar.update()\n",
        "          \n",
        "      batch_bar.close()\n",
        "\n",
        "\n",
        "      print(\"Distance: {:.04f}\".format(total_loss / len(val_loader)))"
      ],
      "metadata": {
        "id": "CQgEqzC3KMCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "pYrvQWRKCqvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets train!"
      ],
      "metadata": {
        "id": "LsA7m_zIQiYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for m in ['cbow', 'skipgram']:\n",
        "    for s in [150, 300, 600]:\n",
        "        print(f\"embedding model: {m}_{s}\")\n",
        "        vocab = torch.load(f'{word2vec_dir}{m}_{s}/vocab.pt')\n",
        "        embedding_model = torch.load(f'{word2vec_dir}{m}_{s}/model.pt')\n",
        "\n",
        "        # embedding from first model layer\n",
        "        embeddings = list(embedding_model.parameters())[0]\n",
        "        embeddings = embeddings.cpu().detach().numpy()\n",
        "\n",
        "        # normalization\n",
        "        norms = (embeddings * 2).sum(axis=1) * (1 / 2)\n",
        "        norms = np.reshape(norms, (len(norms), 1))\n",
        "        embeddings_norm = embeddings / norms\n",
        "        embeddings_norm.shape\n",
        "\n",
        "        def get_word_embedding(word: str):\n",
        "            word_id = vocab[word]\n",
        "            if word_id == 0:\n",
        "                # print(\"Out of vocabulary word\")\n",
        "                return torch.zeros(embeddings_norm.shape[1], 1)\n",
        "\n",
        "            word_vec = embeddings_norm[word_id]\n",
        "            word_vec = np.reshape(word_vec, (len(word_vec), 1))\n",
        "            return word_vec\n",
        "\n",
        "        batch_size = 32\n",
        "        train_sentences, train_scores = df_train.sentence.to_list(), df_train.sentiment_score.to_list()\n",
        "        val_sentences, val_scores = df_val.sentence.to_list(), df_val.sentiment_score.to_list()\n",
        "\n",
        "        train_data = FiQaSamplesWord2Vec('train', train_sentences, train_scores, get_word_embedding, 128)\n",
        "        val_data = FiQaSamplesWord2Vec('dev', val_sentences, val_scores, get_word_embedding, 128)\n",
        "        # test_data = FiQaSamples('test_order.csv')\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=1, collate_fn=FiQaSamplesWord2Vec.collate_fn) # TODO: Define the train loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "        val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=1, collate_fn=FiQaSamplesWord2Vec.collate_fn) # TODO: Define the val loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "        # test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=1, collate_fn=LibriSamplesTest.collate_fn ) # TODO: Define the test loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        model = SentimentRNN(s)\n",
        "        model.to(device)\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            run_train(model, train_loader, batch_size, optimizer, criterion, scheduler, epoch, epochs)\n",
        "            run_validation(model, val_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVBEtItYCvYQ",
        "outputId": "483a2a54-474b-4720-c000-e58efb7137ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding model: cbow_150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10: Train Loss 0.1652, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10: Train Loss 0.1628, Learning Rate 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10: Train Loss 0.1627, Learning Rate 0.0008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10: Train Loss 0.1617, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10: Train Loss 0.1619, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10: Train Loss 0.1593, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10: Train Loss 0.1602, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10: Train Loss 0.1605, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10: Train Loss 0.1595, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10: Train Loss 0.1590, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1686\n",
            "embedding model: cbow_300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10: Train Loss 0.1789, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10: Train Loss 0.1714, Learning Rate 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10: Train Loss 0.1671, Learning Rate 0.0008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10: Train Loss 0.1663, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10: Train Loss 0.1642, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10: Train Loss 0.1615, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10: Train Loss 0.1626, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10: Train Loss 0.1603, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10: Train Loss 0.1586, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10: Train Loss 0.1606, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1717\n",
            "embedding model: cbow_600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10: Train Loss 0.1641, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10: Train Loss 0.1624, Learning Rate 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10: Train Loss 0.1602, Learning Rate 0.0008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10: Train Loss 0.1599, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10: Train Loss 0.1586, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10: Train Loss 0.1609, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10: Train Loss 0.1589, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10: Train Loss 0.1584, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10: Train Loss 0.1578, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10: Train Loss 0.1591, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1673\n",
            "embedding model: skipgram_150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10: Train Loss 0.1743, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10: Train Loss 0.1688, Learning Rate 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10: Train Loss 0.1642, Learning Rate 0.0008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10: Train Loss 0.1625, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10: Train Loss 0.1632, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10: Train Loss 0.1609, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10: Train Loss 0.1614, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10: Train Loss 0.1580, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10: Train Loss 0.1594, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10: Train Loss 0.1606, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1667\n",
            "embedding model: skipgram_300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10: Train Loss 0.1720, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10: Train Loss 0.1662, Learning Rate 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10: Train Loss 0.1653, Learning Rate 0.0008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10: Train Loss 0.1615, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10: Train Loss 0.1602, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10: Train Loss 0.1612, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10: Train Loss 0.1598, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10: Train Loss 0.1599, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10: Train Loss 0.1570, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10: Train Loss 0.1572, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1696\n",
            "embedding model: skipgram_600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10: Train Loss 0.1653, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10: Train Loss 0.1632, Learning Rate 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10: Train Loss 0.1627, Learning Rate 0.0008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10: Train Loss 0.1596, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10: Train Loss 0.1589, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10: Train Loss 0.1577, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10: Train Loss 0.1591, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10: Train Loss 0.1583, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10: Train Loss 0.1573, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10: Train Loss 0.1582, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding model: cbow_150\n",
        "# Epoch 1/10: Train Loss 0.1819, Learning Rate 0.0010\n",
        "# Distance: 0.1845\n",
        "# Epoch 2/10: Train Loss 0.1750, Learning Rate 0.0009\n",
        "# Distance: 0.1792\n",
        "# Epoch 3/10: Train Loss 0.1712, Learning Rate 0.0008\n",
        "# Distance: 0.1772\n",
        "# Epoch 4/10: Train Loss 0.1673, Learning Rate 0.0007\n",
        "# Distance: 0.1732\n",
        "# Epoch 5/10: Train Loss 0.1662, Learning Rate 0.0005\n",
        "# Distance: 0.1723\n",
        "# Epoch 6/10: Train Loss 0.1645, Learning Rate 0.0003\n",
        "# Distance: 0.1711\n",
        "# Epoch 7/10: Train Loss 0.1645, Learning Rate 0.0002\n",
        "# Distance: 0.1724\n",
        "# Epoch 8/10: Train Loss 0.1621, Learning Rate 0.0001\n",
        "# Distance: 0.1730\n",
        "# Epoch 9/10: Train Loss 0.1636, Learning Rate 0.0000\n",
        "# Distance: 0.1727\n",
        "# Epoch 10/10: Train Loss 0.1619, Learning Rate 0.0000\n",
        "# Distance: 0.1726\n",
        "# embedding model: cbow_300\n",
        "# Epoch 1/10: Train Loss 0.1785, Learning Rate 0.0010\n",
        "# Distance: 0.1781\n",
        "# Epoch 2/10: Train Loss 0.1724, Learning Rate 0.0009\n",
        "# Distance: 0.1756\n",
        "# Epoch 3/10: Train Loss 0.1681, Learning Rate 0.0008\n",
        "# Distance: 0.1722\n",
        "# Epoch 4/10: Train Loss 0.1657, Learning Rate 0.0007\n",
        "# Distance: 0.1697\n",
        "# Epoch 5/10: Train Loss 0.1647, Learning Rate 0.0005\n",
        "# Distance: 0.1695\n",
        "# Epoch 6/10: Train Loss 0.1629, Learning Rate 0.0003\n",
        "# Distance: 0.1702\n",
        "# Epoch 7/10: Train Loss 0.1601, Learning Rate 0.0002\n",
        "# Distance: 0.1702\n",
        "# Epoch 8/10: Train Loss 0.1632, Learning Rate 0.0001\n",
        "# Distance: 0.1702\n",
        "# Epoch 9/10: Train Loss 0.1613, Learning Rate 0.0000\n",
        "# Distance: 0.1699\n",
        "# Epoch 10/10: Train Loss 0.1596, Learning Rate 0.0000\n",
        "# Distance: 0.1698\n",
        "# embedding model: cbow_600\n",
        "# Epoch 1/10: Train Loss 0.1974, Learning Rate 0.0010\n",
        "# Distance: 0.1938\n",
        "# Epoch 2/10: Train Loss 0.1878, Learning Rate 0.0009\n",
        "# Distance: 0.1895\n",
        "# Epoch 3/10: Train Loss 0.1800, Learning Rate 0.0008\n",
        "# Distance: 0.1833\n",
        "# Epoch 4/10: Train Loss 0.1764, Learning Rate 0.0007\n",
        "# Distance: 0.1782\n",
        "# Epoch 5/10: Train Loss 0.1709, Learning Rate 0.0005\n",
        "# Distance: 0.1757\n",
        "# Epoch 6/10: Train Loss 0.1687, Learning Rate 0.0003\n",
        "# Distance: 0.1737\n",
        "# Epoch 7/10: Train Loss 0.1685, Learning Rate 0.0002\n",
        "# Distance: 0.1737\n",
        "# Epoch 8/10: Train Loss 0.1657, Learning Rate 0.0001\n",
        "# Distance: 0.1729\n",
        "# Epoch 9/10: Train Loss 0.1654, Learning Rate 0.0000\n",
        "# Distance: 0.1726\n",
        "# Epoch 10/10: Train Loss 0.1658, Learning Rate 0.0000\n",
        "# Distance: 0.1724\n",
        "# embedding model: skipgram_150\n",
        "# Epoch 1/10: Train Loss 0.1640, Learning Rate 0.0010\n",
        "# Distance: 0.1714\n",
        "# Epoch 2/10: Train Loss 0.1615, Learning Rate 0.0009\n",
        "# Distance: 0.1709\n",
        "# Epoch 3/10: Train Loss 0.1612, Learning Rate 0.0008\n",
        "# Distance: 0.1700\n",
        "# Epoch 4/10: Train Loss 0.1599, Learning Rate 0.0007\n",
        "# Distance: 0.1704\n",
        "# Epoch 5/10: Train Loss 0.1591, Learning Rate 0.0005\n",
        "# Distance: 0.1692\n",
        "# Epoch 6/10: Train Loss 0.1605, Learning Rate 0.0003\n",
        "# Distance: 0.1698\n",
        "# Epoch 7/10: Train Loss 0.1597, Learning Rate 0.0002\n",
        "# Distance: 0.1690\n",
        "# Epoch 8/10: Train Loss 0.1592, Learning Rate 0.0001\n",
        "# Distance: 0.1699\n",
        "# Epoch 9/10: Train Loss 0.1576, Learning Rate 0.0000\n",
        "# Distance: 0.1701\n",
        "# Epoch 10/10: Train Loss 0.1573, Learning Rate 0.0000\n",
        "# Distance: 0.1702\n",
        "# embedding model: skipgram_300\n",
        "# Epoch 1/10: Train Loss 0.1912, Learning Rate 0.0010\n",
        "# Distance: 0.1889\n",
        "# Epoch 2/10: Train Loss 0.1827, Learning Rate 0.0009\n",
        "# Distance: 0.1826\n",
        "# Epoch 3/10: Train Loss 0.1770, Learning Rate 0.0008\n",
        "# Distance: 0.1772\n",
        "# Epoch 4/10: Train Loss 0.1725, Learning Rate 0.0007\n",
        "# Distance: 0.1772\n",
        "# Epoch 5/10: Train Loss 0.1681, Learning Rate 0.0005\n",
        "# Distance: 0.1733\n",
        "# Epoch 6/10: Train Loss 0.1670, Learning Rate 0.0003\n",
        "# Distance: 0.1754\n",
        "# Epoch 7/10: Train Loss 0.1656, Learning Rate 0.0002\n",
        "# Distance: 0.1752\n",
        "# Epoch 8/10: Train Loss 0.1636, Learning Rate 0.0001\n",
        "# Distance: 0.1750\n",
        "# Epoch 9/10: Train Loss 0.1639, Learning Rate 0.0000\n",
        "# Distance: 0.1747\n",
        "# Epoch 10/10: Train Loss 0.1623, Learning Rate 0.0000\n",
        "# Distance: 0.1746\n",
        "# embedding model: skipgram_600\n",
        "# Epoch 1/10: Train Loss 0.1654, Learning Rate 0.0010\n",
        "# Distance: 0.1697\n",
        "# Epoch 2/10: Train Loss 0.1619, Learning Rate 0.0009\n",
        "# Distance: 0.1710\n",
        "# Epoch 3/10: Train Loss 0.1615, Learning Rate 0.0008\n",
        "# Distance: 0.1723\n",
        "# Epoch 4/10: Train Loss 0.1602, Learning Rate 0.0007\n",
        "# Distance: 0.1704\n",
        "# Epoch 5/10: Train Loss 0.1587, Learning Rate 0.0005\n",
        "# Distance: 0.1700\n",
        "# Epoch 6/10: Train Loss 0.1612, Learning Rate 0.0003\n",
        "# Distance: 0.1686\n",
        "# Epoch 7/10: Train Loss 0.1589, Learning Rate 0.0002\n",
        "# Distance: 0.1692\n",
        "# Epoch 8/10: Train Loss 0.1581, Learning Rate 0.0001\n",
        "# Distance: 0.1706\n",
        "# Epoch 9/10: Train Loss 0.1566, Learning Rate 0.0000\n",
        "# Distance: 0.1706\n",
        "# Epoch 10/10: Train Loss 0.1569, Learning Rate 0.0000\n",
        "#                                                                Distance: 0.1709"
      ],
      "metadata": {
        "id": "F7doObBiEB5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Loss: 1.8752116763900066\n",
        "# Val Loss: 0.17607808538845607\n",
        "# Train Loss: 0.18389656677328306\n",
        "# Val Loss: 0.17218721125807082\n",
        "# Train Loss: 0.18046144164841751\n",
        "# Val Loss: 0.16996091178485326\n",
        "# Train Loss: 0.17665653187653113\n",
        "# Val Loss: 0.17563885237489427\n",
        "# Train Loss: 0.1673661090176681\n",
        "# Val Loss: 0.17287699239594595\n",
        "# Train Loss: 0.1738741408134329\n",
        "# Val Loss: 0.17703682609966823\n",
        "# Train Loss: 0.16847693868752184\n",
        "# Val Loss: 0.17194960585662297\n",
        "# Train Loss: 0.16885116619282756\n",
        "# Val Loss: 0.16994784346648625\n",
        "# Train Loss: 0.16396602397334986\n",
        "# Val Loss: 0.17066440199102675\n",
        "# Train Loss: 0.16824036682474203\n",
        "# Val Loss: 0.1702498346567154"
      ],
      "metadata": {
        "id": "6UGDcho1KvF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SentimentRNN - Glove"
      ],
      "metadata": {
        "id": "JENYFRnUIFvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility functions for Glove"
      ],
      "metadata": {
        "id": "z_sQjq-VKZWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GLOVE_EMBEDDING_SIZE = 100"
      ],
      "metadata": {
        "id": "JTCJxA7QaPNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Glove model--for some reason it doesnt load when importing from .py files so Im including it here\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class GloVe(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_size, x_max, alpha):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=embedding_size,\n",
        "            sparse=True\n",
        "        )\n",
        "        self.weight_tilde = nn.Embedding(\n",
        "            num_embeddings=vocab_size,\n",
        "            embedding_dim=embedding_size,\n",
        "            sparse=True\n",
        "        )\n",
        "        self.bias = nn.Parameter(\n",
        "            torch.randn(\n",
        "                vocab_size,\n",
        "                dtype=torch.float,\n",
        "            )\n",
        "        )\n",
        "        self.bias_tilde = nn.Parameter(\n",
        "            torch.randn(\n",
        "                vocab_size,\n",
        "                dtype=torch.float,\n",
        "            )\n",
        "        )\n",
        "        self.weighting_func = lambda x: (x / x_max).float_power(alpha).clamp(0, 1)\n",
        "    \n",
        "    def forward(self, i, j, x):\n",
        "        loss = torch.mul(self.weight(i), self.weight_tilde(j)).sum(dim=1)\n",
        "        loss = (loss + self.bias[i] + self.bias_tilde[j] - x.log()).square()\n",
        "        loss = torch.mul(self.weighting_func(x), loss).mean()\n",
        "        return loss"
      ],
      "metadata": {
        "id": "XZ5nGBAWQvrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip3 install --upgrade gensim --user\n",
        "\n",
        "drive_path = '/content/drive/MyDrive/'\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "import argparse\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import yaml\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import gensim.models\n",
        "\n",
        "import h5py\n",
        "import sys\n",
        "import numpy as np \n",
        "sys.path.insert(0,'/content/drive/MyDrive/11785_Project/Programming/GloveCode')\n",
        "\n",
        "\n",
        "def load_config():\n",
        "    with open('/content/drive/MyDrive/11785_Project/Programming/GloveCode/config.yaml') as parameters:\n",
        "            config_dict = yaml.safe_load(parameters)\n",
        "    config = argparse.Namespace()\n",
        "    for key, value in config_dict.items():\n",
        "        setattr(config, key, value)\n",
        "    return config\n",
        "\n",
        "\n",
        "def make_vectors():\n",
        "    config = load_config()\n",
        "    with open(os.path.join('/content/drive/MyDrive/11785_Project/Programming/GloveCode', \"vocab.pkl\"), \"rb\") as f:\n",
        "        vocab = pickle.load(f)\n",
        "\n",
        "    model = GloVe(\n",
        "        vocab_size=config.vocab_size,\n",
        "        embedding_size=config.embedding_size,\n",
        "        x_max=config.x_max,\n",
        "        alpha=config.alpha\n",
        "    )\n",
        "    model.load_state_dict(torch.load('/content/drive/MyDrive/11785_Project/Programming/GloveCode/glove-output'))\n",
        "    keyed_vectors = gensim.models.keyedvectors.KeyedVectors(vector_size=config.embedding_size)\n",
        "    keyed_vectors.add_vectors(\n",
        "        keys=[vocab.get_token(index) for index in range(len(vocab))],\n",
        "        weights=(model.weight.weight.detach()\n",
        "            + model.weight_tilde.weight.detach()).numpy()\n",
        "    )\n",
        "\n",
        "    return keyed_vectors, config.embedding_size, vocab\n",
        "\n",
        "\n",
        "def get_word_embedding(word: str):\n",
        "    keyed_vectors, emb_size, vocab=make_vectors()\n",
        "    word_id = vocab[word]\n",
        "    if word_id == -1:\n",
        "        # print(\"Out of vocabulary word\")\n",
        "        return torch.zeros(emb_size, 1)\n",
        "\n",
        "    word_vec = keyed_vectors.get_vector(word)\n",
        "    word_vec = np.reshape(word_vec, (len(word_vec), 1))\n",
        "    return word_vec\n",
        "\n",
        "for w in ['burden', 'deliverable', 'domain']:\n",
        "    embedding = get_word_embedding(w)\n",
        "\n",
        "    print(f'{w} has embedding {embedding.shape}')\n",
        "\n",
        "# _dir = '/content/drive/MyDrive/11785-project/word2vec/'\n",
        "# vocab = torch.load(f'{word2vec_dir}vocab.pt')\n",
        "# model = torch.load(f'{word2vec_dir}model.pt')\n",
        "\n",
        "# # embedding from first model layer\n",
        "# embeddings = list(model.parameters())[0]\n",
        "# embeddings = embeddings.cpu().detach().numpy()\n",
        "\n",
        "# # normalization\n",
        "# norms = (embeddings * 2).sum(axis=1) * (1 / 2)\n",
        "# norms = np.reshape(norms, (len(norms), 1))\n",
        "# embeddings_norm = embeddings / norms\n",
        "# embeddings_norm.shape\n",
        "\n",
        "# def get_word_embedding(word: str):\n",
        "#     word_id = vocab[word]\n",
        "#     if word_id == 0:\n",
        "#         # print(\"Out of vocabulary word\")\n",
        "#         return torch.zeros(embeddings_norm.shape[1], 1)\n",
        "\n",
        "#     word_vec = embeddings_norm[word_id]\n",
        "#     word_vec = np.reshape(word_vec, (len(word_vec), 1))\n",
        "#     return word_vec\n",
        "\n",
        "# for w in ['burden', 'deliverable', 'domain']:\n",
        "#     embedding = get_word_embedding(w)\n",
        "\n",
        "#     print(f'{w} has embedding {embedding.shape}')"
      ],
      "metadata": {
        "id": "x8n2VJ8TKGjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61d19fb8-c285-4e01-fd82-73d8cb6dc799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "burden has embedding (100, 1)\n",
            "deliverable has embedding (100, 1)\n",
            "domain has embedding (100, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "e3SvORIZKM1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FiQaSamplesWord2Vec(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, partition, sentences, sentiment_scores, get_word_embedding, max_len):\n",
        "    self.sentences = sentences\n",
        "    self.sentiment_scores = sentiment_scores\n",
        "    self.model = get_word_embedding\n",
        "    assert len(sentences) == len(sentiment_scores)\n",
        "    self.length = len(self.sentences)\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    sentence = self.sentences[index]\n",
        "    score = self.sentiment_scores[index]\n",
        "    tokens = sentence\n",
        "    # Tokens is a list of strings\n",
        "    embedding = np.array([np.array(self.model(token)) for token in sentence.split()])\n",
        "    return torch.tensor(embedding).squeeze(), torch.tensor(score, dtype = torch.float)\n",
        "\n",
        "  def collate_fn(batch):\n",
        "    batch_x = [emb for emb, y in batch]\n",
        "    batch_y = [y for emb, y in batch]\n",
        "\n",
        "    batch_x_pad = pad_sequence(batch_x, batch_first = True) \n",
        "    lengths_x = [x.shape[0] for x in batch_x]\n",
        "\n",
        "    return batch_x_pad, lengths_x, torch.tensor(batch_y)"
      ],
      "metadata": {
        "id": "amO-GkA1KM1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_sentences, train_scores = df_train.sentence.to_list(), df_train.sentiment_score.to_list()\n",
        "val_sentences, val_scores = df_val.sentence.to_list(), df_val.sentiment_score.to_list()\n",
        "\n",
        "train_data = FiQaSamplesWord2Vec('train', train_sentences, train_scores, get_word_embedding, 128)\n",
        "val_data = FiQaSamplesWord2Vec('dev', val_sentences, val_scores, get_word_embedding, 128)\n",
        "# test_data = FiQaSamples('test_order.csv')\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=1, collate_fn=FiQaSamplesWord2Vec.collate_fn) # TODO: Define the train loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=1, collate_fn=FiQaSamplesWord2Vec.collate_fn) # TODO: Define the val loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "# test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=1, collate_fn=LibriSamplesTest.collate_fn ) # TODO: Define the test loader. Remember to pass in a parameter (function) for the collate_fn argument \n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Batch size: \", batch_size)\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "# print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))\n",
        "print(\"Device: \", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400706ff-7b03-4fc4-db4d-a68e3d7f3dda",
        "id": "XFADv-TKKM1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  32\n",
            "Train dataset samples = 911, batches = 29\n",
            "Val dataset samples = 200, batches = 7\n",
            "Device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ],
      "metadata": {
        "id": "ABSMVu2iKM1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/code/arunmohan003/sentiment-analysis-using-lstm-pytorch/notebook\n",
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SentimentRNN,self).__init__()\n",
        "        self.hidden_size = 128\n",
        "        self.lstm = nn.LSTM(input_size=GLOVE_EMBEDDING_SIZE, hidden_size=self.hidden_size, num_layers=2, batch_first=True)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc = nn.Linear(self.hidden_size, 1)\n",
        "        \n",
        "    def forward(self, x, lx):\n",
        "        # x is a list of vector (num of tokens, emb_dim - hyperparam)\n",
        "        batch_size = x.shape[0]\n",
        "        packed_input = pack_padded_sequence(x, lx, batch_first = True, enforce_sorted=False) \n",
        "        output, (hidden_state, cell_state) = self.lstm(packed_input) \n",
        "        out, lengths  = pad_packed_sequence(output, batch_first = True)\n",
        "        out = out.contiguous().view(-1, self.hidden_size)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        out = out.view(batch_size, -1)\n",
        "        out = out[:, -1] # get last batch of labels\n",
        "        return out, lengths\n"
      ],
      "metadata": {
        "id": "Z3d2-A_mKM1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and validation functions"
      ],
      "metadata": {
        "id": "4YTsksT_KM1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_train(model, train_loader, batch_size, optimizer, criterion, scheduler, epoch, epochs):\n",
        "  torch.cuda.empty_cache()\n",
        "  model.train()\n",
        "  batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "\n",
        "  num_correct = 0\n",
        "  total_loss = 0\n",
        "\n",
        "  for i, (x, lx, y) in enumerate(train_loader):\n",
        "      torch.cuda.empty_cache() # Use this often\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      outputs, lengths = model(x, lx)\n",
        "      loss = criterion(outputs, y)\n",
        "      total_loss += float(loss)\n",
        "      batch_bar.set_postfix(\n",
        "          loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "          lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "      \n",
        "      # Another couple things you need for FP16. \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "      batch_bar.update() # Update tqdm bar\n",
        "  scheduler.step() # We told scheduler T_max that we'd call step() (len(train_loader) * epochs) many times.\n",
        "  batch_bar.close() # You need this to close the tqdm bar\n",
        "\n",
        "  print(\"Epoch {}/{}: Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n",
        "      epoch + 1,\n",
        "      epochs,\n",
        "      float(total_loss / len(train_loader)),\n",
        "      float(optimizer.param_groups[0]['lr'])))\n",
        "  \n",
        "\n",
        "\n",
        "def run_validation(model, val_loader):\n",
        "  torch.cuda.empty_cache() # Use this often\n",
        "  model.eval()\n",
        "  batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "  total_loss = 0\n",
        "  with torch.no_grad():\n",
        "      for i, (x, lx, y) in enumerate(val_loader):\n",
        "          torch.cuda.empty_cache() # Use this often\n",
        "          x = x.to(device)\n",
        "          y = y.to(device)\n",
        "\n",
        "          outputs, lengths = model(x, lx)\n",
        "          loss = criterion(outputs, y)\n",
        "          total_loss += loss\n",
        "          batch_bar.set_postfix(dist=\"{:.04f}\".format(total_loss / (i + 1)))\n",
        "\n",
        "          batch_bar.update()\n",
        "          \n",
        "      batch_bar.close()\n",
        "\n",
        "\n",
        "      print(\"Distance: {:.04f}\".format(total_loss / len(val_loader)))"
      ],
      "metadata": {
        "id": "SGixGi91KM1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "epochs = 10\n",
        "\n",
        "model = SentimentRNN()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "h1G0Tgh6KM1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets train!"
      ],
      "metadata": {
        "id": "cvc7xtIgKM1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    run_train(model, train_loader, batch_size, optimizer, criterion, scheduler, epoch, epochs)\n",
        "    run_validation(model, val_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c3c84b4-bdf8-4c78-cc49-32c213ee4822",
        "id": "9SO0hy6ZKM1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10: Train Loss 0.1862, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10: Train Loss 0.1776, Learning Rate 0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10: Train Loss 0.1731, Learning Rate 0.0008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10: Train Loss 0.1686, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10: Train Loss 0.1652, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10: Train Loss 0.1645, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10: Train Loss 0.1617, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10: Train Loss 0.1625, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10: Train Loss 0.1609, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10: Train Loss 0.1619, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 0.1738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    }
  ]
}